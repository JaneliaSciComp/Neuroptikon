Centrality
==========

>>> from networkx import *

>>> K=krackhardt_kite_graph()
>>> P3=path_graph(3)
>>> P4=path_graph(4)
>>> K5=complete_graph(5)
>>> C4=cycle_graph(4)
>>> T=balanced_tree(r=2, h=2)
>>> Gb = Graph()
>>> Gb.add_edges_from([(0,1), (0,2), (1,3), (2,3), (2,4), (4,5), (3,5)])


>>> F=Graph() # Florentine families
>>> F.add_edge('Acciaiuoli','Medici')
>>> F.add_edge('Castellani','Peruzzi')
>>> F.add_edge('Castellani','Strozzi')
>>> F.add_edge('Castellani','Barbadori')
>>> F.add_edge('Medici','Barbadori')
>>> F.add_edge('Medici','Ridolfi')
>>> F.add_edge('Medici','Tornabuoni')
>>> F.add_edge('Medici','Albizzi')
>>> F.add_edge('Medici','Salviati')
>>> F.add_edge('Salviati','Pazzi')
>>> F.add_edge('Peruzzi','Strozzi')
>>> F.add_edge('Peruzzi','Bischeri')
>>> F.add_edge('Strozzi','Ridolfi')
>>> F.add_edge('Strozzi','Bischeri')
>>> F.add_edge('Ridolfi','Tornabuoni')
>>> F.add_edge('Tornabuoni','Guadagni')
>>> F.add_edge('Albizzi','Ginori')
>>> F.add_edge('Albizzi','Guadagni')
>>> F.add_edge('Bischeri','Guadagni')
>>> F.add_edge('Guadagni','Lamberteschi')


Degree Centrality
------------------

>>> d=degree_centrality(K5)
>>> for v in K5:
...     print "%0.2d %5.3f"%(v,d[v])
00 1.000
01 1.000
02 1.000
03 1.000
04 1.000

>>> d=degree_centrality(P3)
>>> for v in P3:
...     print "%0.2d %5.3f"%(v,d[v])
00 0.500
01 1.000
02 0.500


>>> d=degree_centrality(K)
>>> for v in K:
...     print "%0.2d %5.3f"%(v,d[v])
00 0.444
01 0.444
02 0.333
03 0.667
04 0.333
05 0.556
06 0.556
07 0.333
08 0.222
09 0.111


>>> d=degree_centrality(F)
>>> for v in sorted(F):
...     print "%-13s %5.3f"%(v,d[v])
Acciaiuoli    0.071
Albizzi       0.214
Barbadori     0.143
Bischeri      0.214
Castellani    0.214
Ginori        0.071
Guadagni      0.286
Lamberteschi  0.071
Medici        0.429
Pazzi         0.071
Peruzzi       0.214
Ridolfi       0.214
Salviati      0.143
Strozzi       0.286
Tornabuoni    0.214

Closeness Centrality
--------------------

>>> c=closeness_centrality(K5)
>>> for v in K5:
...     print "%0.2d %5.3f"%(v,c[v])
00 1.000
01 1.000
02 1.000
03 1.000
04 1.000

>>> c=closeness_centrality(P3)
>>> for v in P3:
...     print "%0.2d %5.3f"%(v,c[v])
00 0.667
01 1.000
02 0.667


>>> c=closeness_centrality(K)
>>> for v in K:
...     print "%0.2d %5.3f"%(v,c[v])
00 0.529
01 0.529
02 0.500
03 0.600
04 0.500
05 0.643
06 0.643
07 0.600
08 0.429
09 0.310


>>> c=closeness_centrality(F)
>>> for v in sorted(F):
...     print "%-13s %5.3f"%(v,c[v])
Acciaiuoli    0.368
Albizzi       0.483
Barbadori     0.438
Bischeri      0.400
Castellani    0.389
Ginori        0.333
Guadagni      0.467
Lamberteschi  0.326
Medici        0.560
Pazzi         0.286
Peruzzi       0.368
Ridolfi       0.500
Salviati      0.389
Strozzi       0.438
Tornabuoni    0.483


Weighted Closeness
------------------

>>> XG=Graph()
>>> XG.add_weighted_edges_from([('s','u',10) ,('s','x',5) ,('u','v',1) ,('u','x',2) ,('v','y',1) ,('x','u',3) ,('x','v',5) ,('x','y',2) ,('y','s',7) ,('y','v',6)])
>>> c=closeness_centrality(XG,weighted_edges=True)
>>> for v in XG.nodes():
...     print "%s %5.3f"%(v,c[v])
y 0.200
x 0.286
s 0.138
u 0.235
v 0.200



Betweenness
-----------
>>> b=betweenness_centrality(K5)
>>> for v in K5:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 0.000
02 0.000
03 0.000
04 0.000

>>> b=betweenness_centrality(P3)
>>> for v in P3:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 1.000
02 0.000


>>> b=betweenness_centrality(K)
>>> for v in K:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.023
01 0.023
02 0.000
03 0.102
04 0.000
05 0.231
06 0.231
07 0.389
08 0.222
09 0.000


>>> b=betweenness_centrality(F)
>>> for v in sorted(F):
...     print "%-13s %5.3f"%(v,b[v])
Acciaiuoli    0.000
Albizzi       0.212
Barbadori     0.093
Bischeri      0.104
Castellani    0.055
Ginori        0.000
Guadagni      0.255
Lamberteschi  0.000
Medici        0.522
Pazzi         0.000
Peruzzi       0.022
Ridolfi       0.114
Salviati      0.143
Strozzi       0.103
Tornabuoni    0.092


Unnormalized

>>> b=betweenness_centrality(K5,normalized=False)
>>> for v in K5:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 0.000
02 0.000
03 0.000
04 0.000

>>> b=betweenness_centrality(P3,normalized=False)
>>> for v in P3:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 2.000
02 0.000


>>> b=betweenness_centrality(K,normalized=False)
>>> for v in K:
...     print "%0.2d %5.3f"%(v,b[v])
00 1.667
01 1.667
02 0.000
03 7.333
04 0.000
05 16.667
06 16.667
07 28.000
08 16.000
09 0.000



>>> b=betweenness_centrality(F,normalized=False)
>>> for v in sorted(F):
...     print "%-13s %5.3f"%(v,b[v])
Acciaiuoli    0.000
Albizzi       38.667
Barbadori     17.000
Bischeri      19.000
Castellani    10.000
Ginori        0.000
Guadagni      46.333
Lamberteschi  0.000
Medici        95.000
Pazzi         0.000
Peruzzi       4.000
Ridolfi       20.667
Salviati      26.000
Strozzi       18.667
Tornabuoni    16.667


Alternative Betweenness - allow for sources (subgraph)
------------------------------------------------------
>>> b=betweenness_centrality_source(K5)
>>> for v in K5:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 0.000
02 0.000
03 0.000
04 0.000

>>> b=betweenness_centrality_source(P3)
>>> for v in P3:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 1.000
02 0.000


>>> b=betweenness_centrality_source(K)
>>> for v in K:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.023
01 0.023
02 0.000
03 0.102
04 0.000
05 0.231
06 0.231
07 0.389
08 0.222
09 0.000


>>> b=betweenness_centrality_source(F)
>>> for v in sorted(F):
...     print "%-13s %5.3f"%(v,b[v])
Acciaiuoli    0.000
Albizzi       0.212
Barbadori     0.093
Bischeri      0.104
Castellani    0.055
Ginori        0.000
Guadagni      0.255
Lamberteschi  0.000
Medici        0.522
Pazzi         0.000
Peruzzi       0.022
Ridolfi       0.114
Salviati      0.143
Strozzi       0.103
Tornabuoni    0.092


Unnormalized

>>> b=betweenness_centrality_source(K5,normalized=False)
>>> for v in K5:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 0.000
02 0.000
03 0.000
04 0.000

>>> b=betweenness_centrality_source(P3,normalized=False)
>>> for v in P3:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 2.000
02 0.000


>>> b=betweenness_centrality_source(K,normalized=False)
>>> for v in K:
...     print "%0.2d %5.3f"%(v,b[v])
00 1.667
01 1.667
02 0.000
03 7.333
04 0.000
05 16.667
06 16.667
07 28.000
08 16.000
09 0.000



>>> b=betweenness_centrality_source(F,normalized=False)
>>> for v in sorted(F):
...     print "%-13s %5.3f"%(v,b[v])
Acciaiuoli    0.000
Albizzi       38.667
Barbadori     17.000
Bischeri      19.000
Castellani    10.000
Ginori        0.000
Guadagni      46.333
Lamberteschi  0.000
Medici        95.000
Pazzi         0.000
Peruzzi       4.000
Ridolfi       20.667
Salviati      26.000
Strozzi       18.667
Tornabuoni    16.667




Load
----
>>> b=load_centrality(K5)
>>> for v in K5:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 0.000
02 0.000
03 0.000
04 0.000

>>> b=load_centrality(P3)
>>> for v in P3:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 1.000
02 0.000


>>> b=load_centrality(K)
>>> for v in K:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.023
01 0.023
02 0.000
03 0.102
04 0.000
05 0.231
06 0.231
07 0.389
08 0.222
09 0.000


>>> b=load_centrality(F)
>>> for v in sorted(F):
...     print "%-13s %5.3f"%(v,b[v])
Acciaiuoli    0.000
Albizzi       0.211
Barbadori     0.093
Bischeri      0.104
Castellani    0.055
Ginori        0.000
Guadagni      0.251
Lamberteschi  0.000
Medici        0.522
Pazzi         0.000
Peruzzi       0.022
Ridolfi       0.117
Salviati      0.143
Strozzi       0.106
Tornabuoni    0.090


Unnormalized

>>> b=load_centrality(K5,normalized=False)
>>> for v in K5:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 0.000
02 0.000
03 0.000
04 0.000

>>> b=load_centrality(P3,normalized=False)
>>> for v in P3:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 2.000
02 0.000


>>> b=load_centrality(K,normalized=False)
>>> for v in K:
...     print "%0.2d %5.3f"%(v,b[v])
00 1.667
01 1.667
02 0.000
03 7.333
04 0.000
05 16.667
06 16.667
07 28.000
08 16.000
09 0.000



>>> b=load_centrality(F,normalized=False)
>>> for v in sorted(F):
...     print "%-13s %5.3f"%(v,b[v])
Acciaiuoli    0.000
Albizzi       38.333
Barbadori     17.000
Bischeri      19.000
Castellani    10.000
Ginori        0.000
Guadagni      45.667
Lamberteschi  0.000
Medici        95.000
Pazzi         0.000
Peruzzi       4.000
Ridolfi       21.333
Salviati      26.000
Strozzi       19.333
Tornabuoni    16.333

Difference Between Load and Betweenness
---------------------------------------
The smallest graph that shows the difference between
load and betweenness is G=ladder_graph(3) (Graph B below)

Graph A and B are from Tao Zhou, Jian-Guo Liu, Bing-Hong Wang:
Comment on ``Scientific collaboration networks. II. Shortest paths,
weighted networks, and centrality". http://arxiv.org/pdf/physics/0511084

Notice that unlike here, their calculation adds to 1 to the betweennes
of every node i for every path from i to every other node.  This is
exactly what it should be, based on Eqn. (1) in their paper: the eqn
is B(v) = \sum_{s\neq t, s\neq v}{\frac{\sigma_{st}(v)}{\sigma_{st}}},
therefore, they allow v to be the target node.

We follow Brandes 2001, who follows Freeman 1977 that make the sum for
betweenness of v exclude paths where v is either the source or target
node.  To agree with their numbers, we must additionally, remove edge
(4,8) from the graph, see AC example following (there is a mistake
in the figure in their paper - personal communication).

>>> A = Graph()
>>> A.add_edges_from([(0,1), (1,2), (1,3), (2,4), (3,5), (4,6), (4,7), (4,8), (5,8), (6,9), (7,9), (8,9)])
>>> b = betweenness_centrality(A,normalized=False)
>>> for v in A:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 21.333
02 19.333
03 8.000
04 29.667
05 10.667
06 2.333
07 2.333
08 18.000
09 6.333

>>> AC = Graph()
>>> AC.add_edges_from([(0,1), (1,2), (1,3), (2,4), (3,5), (4,6), (4,7), (5,8), (6,9), (7,9), (8,9)])
>>> b = betweenness_centrality(AC,normalized=False)
>>> for v in AC:
...     print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 25.333
02 19.333
03 12.667
04 21.000
05 12.000
06 5.667
07 5.667
08 12.667
09 15.667

>>> B = Graph() # ladder_graph(3)
>>> B.add_edges_from([(0,1), (0,2), (1,3), (2,3), (2,4), (4,5), (3,5)])
>>> b = betweenness_centrality(B,normalized=False)
>>> for v in B:
...     print "%0.2d %5.3f"%(v,b[v])
00 1.667
01 1.667
02 6.667
03 6.667
04 1.667
05 1.667

>>> b = load_centrality(B,normalized=False)
>>> for v in B:
...     print "%0.2d %5.3f"%(v,b[v])
00 1.750
01 1.750
02 6.500
03 6.500
04 1.750
05 1.750


b = betweenness_centrality(B, normalized=False, sources=[0])
for v in Gb.nodes():
    print "%0.2d %5.3f"%(v,b[v])
00 0.000
01 0.833
02 2.167
03 0.667
04 0.333
05 0.000


Weighted Betweenness
--------------------
>>> XG=DiGraph()
>>> XG.add_weighted_edges_from([('s','u',10) ,('s','x',5) ,('u','v',1) ,('u','x',2) ,('v','y',1) ,('x','u',3) ,('x','v',5) ,('x','y',2) ,('y','s',7) ,('y','v',6)])
>>> b=load_centrality(XG,'s',weighted_edges=True)
>>> print "%s"%b
0.333333333333


>>> b=load_centrality(XG,weighted_edges=True,normalized=False)
>>> for v,bb in b.items():
...     print "%s %s"%(v,bb)
y 5.0
x 5.0
s 4.0
u 2.0
v 2.0

>>> b=betweenness_centrality(XG,weighted_edges=True,normalized=False)
>>> for v,bb in b.items():
...     print "%s %s"%(v,bb)
y 5.0
x 5.0
s 4.0
u 2.0
v 2.0


>>> b=betweenness_centrality_source(XG,weighted_edges=True,normalized=False)
>>> for v,bb in b.items():
...     print "%s %s"%(v,bb)
y 5.0
x 5.0
s 4.0
u 2.0
v 2.0





Edge Betweenness
----------------

>>> b = edge_betweenness(C4, normalized=False)
>>> for v in C4.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 4.000
(00, 03) 4.000
(01, 02) 4.000
(02, 03) 4.000

>>> b = edge_betweenness(P4, normalized=False)
>>> for v in P4.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 6.000
(01, 02) 8.000
(02, 03) 6.000

>>> b = edge_betweenness(K5, normalized=False)
>>> for v in K5.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 2.000
(00, 02) 2.000
(00, 03) 2.000
(00, 04) 2.000
(01, 02) 2.000
(01, 03) 2.000
(01, 04) 2.000
(02, 03) 2.000
(02, 04) 2.000
(03, 04) 2.000

>>> b = edge_betweenness(T, normalized=False)
>>> for v in T.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 24.000
(00, 02) 24.000
(01, 03) 12.000
(01, 04) 12.000
(02, 05) 12.000
(02, 06) 12.000

>>> b = edge_betweenness(T, sources=[0], normalized=False)
>>> for v in T.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 3.000
(00, 02) 3.000
(01, 03) 1.000
(01, 04) 1.000
(02, 05) 1.000
(02, 06) 1.000

>>> digraphT = DiGraph()
>>> digraphT.add_edges_from([(0,1), (0,2), (1,3), (1,4), (2,5), (2,6)])
>>> b = edge_betweenness(digraphT, sources=[0], normalized=False)
>>> for v in digraphT.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 3.000
(00, 02) 3.000
(01, 03) 1.000
(01, 04) 1.000
(02, 05) 1.000
(02, 06) 1.000

>>> digraphT2 = DiGraph()
>>> digraphT2.add_edges_from([(0,1), (1,0), (0,2), (1,3), (1,4), (2,5), (2,6)])
>>> b = edge_betweenness(digraphT2, sources=[0], normalized=False)
>>> for v in digraphT2.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 3.000
(00, 02) 3.000
(01, 00) 0.000
(01, 03) 1.000
(01, 04) 1.000
(02, 05) 1.000
(02, 06) 1.000

>>> digraphT2 = DiGraph()
>>> digraphT2.add_edges_from([(0,1), (1,0), (0,2), (1,3), (1,4), (2,5), (2,6)])
>>> b = edge_betweenness(digraphT2, sources=[0,1], normalized=False)
>>> for v in digraphT2.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 3.000
(00, 02) 6.000
(01, 00) 4.000
(01, 03) 2.000
(01, 04) 2.000
(02, 05) 2.000
(02, 06) 2.000

>>> XT = Graph()
>>> XT.add_weighted_edges_from([(0,1,10), (0,2,10), (1,3,10), (1,4,10), (2,5,10), (2,6,10)])
>>> b = edge_betweenness(XT, sources=[0], normalized=False, weighted_edges=True)
>>> for v in XT.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v[0:2]])
(00, 01) 3.000
(00, 02) 3.000
(01, 03) 1.000
(01, 04) 1.000
(02, 05) 1.000
(02, 06) 1.000

>>> b = edge_betweenness(Gb, normalized=False, sources=[0])
>>> for v in Gb.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 1.833
(00, 02) 3.167
(01, 03) 0.833
(02, 03) 0.833
(02, 04) 1.333
(03, 05) 0.667
(04, 05) 0.333


Edge Load
---------
>>> b = edge_load(C4)
>>> for v in C4.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 6.000
(00, 03) 6.000
(01, 02) 6.000
(02, 03) 6.000

>>> b = edge_load(P4)
>>> for v in P4.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 6.000
(01, 02) 8.000
(02, 03) 6.000

>>> b = edge_load(K5)
>>> for v in K5.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 5.000
(00, 02) 5.000
(00, 03) 5.000
(00, 04) 5.000
(01, 02) 5.000
(01, 03) 5.000
(01, 04) 5.000
(02, 03) 5.000
(02, 04) 5.000
(03, 04) 5.000

>>> b = edge_load(T)
>>> for v in T.edges():
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 24.000
(00, 02) 24.000
(01, 03) 12.000
(01, 04) 12.000
(02, 05) 12.000
(02, 06) 12.000

>>> G = Graph()
>>> eList = [(0, 1, 5), (0, 2, 4), (0, 3, 3), (0, 4, 2), (1, 2, 4), (1, 3, 1), (1, 4, 3), (2, 4, 5), (3, 4, 4)]
>>> G.add_weighted_edges_from(eList)
>>> b = edge_betweenness(G, normalized=False, weighted_edges=True)
>>> for v in G.edges(data=False):
...     print "(%0.2d, %0.2d) %5.3f"%(v[0], v[1], b[v])
(00, 01) 0.000
(00, 02) 2.000
(00, 03) 4.000
(00, 04) 2.000
(01, 02) 4.000
(01, 03) 7.000
(01, 04) 3.000
(02, 04) 2.000
(03, 04) 1.000

